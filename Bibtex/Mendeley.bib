@article{KrzanowskiVer2006,
author = {{Krzanowski Ver}, R},
file = {:home/wcravens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krzanowski Ver - 2006 - Burst (of packets) and Burstiness.pdf:pdf},
title = {{Burst (of packets) and Burstiness}},
year = {2006}
}
@article{Cheysson,
abstract = {In this paper, we study the time series generated by the event counts of the stationary Hawkes process. Using the cluster properties of the stationary Hawkes process, we prove an upper bound for its strong-mixing coefficient, and for its count series', provided that the reproduction kernel has a finite (1 + $\beta$)-th order moment (for a $\beta$ > 0). When the exact locations of points are not observed, but only counts over fixed time intervals, we propose a spectral approach to the estimation of Hawkes processes, based on Whittle's likelihood. This approach provides consistent and asymptotically normal estimates provided common regularity conditions on the reproduction kernel. Simulated datasets illustrate the performances of the estimation, notably, of the Hawkes reproduction mean and kernel, even with relatively large time intervals.},
author = {Cheysson, Felix and Lang, Gabriel},
file = {:home/wcravens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cheysson, Lang - Unknown - Strong-mixing rates for Hawkes processes and application to Whittle estimation from count data.pdf:pdf},
keywords = {Bartlett spectrum,Hawkes process,Strong mixing,Time series,Whittle estimation},
title = {{Strong-mixing rates for Hawkes processes and application to Whittle estimation from count data}},
url = {https://hal.archives-ouvertes.fr/hal-03117924}
}
@article{Krispin2019,
abstract = {The decomposition of time series This book introduces you to time series analysis and forecasting with R; this is one of the key fields in statistical programming and includes techniques for analyzing data to extract meaningful insights. You will explore methods, such as prediction with time series analysis, and identify the relationship between each data point in the series. Cover; Title Page; Copyright and Credits; Dedication; About Packt; Contributors; Table of Contents; Preface; Chapter 1: Introduction to Time Series Analysis and R; Technical requirements; Time series data; Historical background of time series analysis; Time series analysis; Learning with real-life examples; Getting started with R; Installing R; A brief introduction to R; R operators; Assignment operators; Arithmetic operators; Logical operators; Relational operators; The R package; Installation and maintenance of a package; Loading a package in the R working environment; The key packages VariablesImporting and loading data to R; Flat files; Web API; R datasets; Working and manipulating data; Querying the data; Help and additional resources; Summary; Chapter 2: Working with Date and Time Objects; Technical requirements; The date and time formats; Date and time objects in R; Creating date and time objects; Importing date and time objects; Reformatting and converting date objects; Handling numeric date objects; Reformatting and conversion of time objects; Time zone setting; Creating a date or time index; Manipulation of date and time with the lubridate package Reformatting date and time objects -- the lubridate wayUtility functions for date and time objects; Summary; Chapter 3: The Time Series Object; Technical requirement; The Natural Gas Consumption dataset; The attributes of the ts class; Multivariate time series objects; Creating a ts object; Creating an mts object; Setting the series frequency; Data manipulation of ts objects; The window function; Aggregating ts objects; Creating lags and leads for ts objects; Visualizing ts and mts objects; The plot.ts function; The dygraphs package; The TSstudio package; Summary Chapter 4: Working with zoo and xts ObjectsTechnical requirement; The zoo class; The zoo class attributes; The index of the zoo object; Working with date and time objects; Creating a zoo object; Working with multiple time series objects; The xts class; The xts class attributes; The xts functionality; The periodicity function; Manipulating the object index; Subsetting an xts object based on the index properties; Manipulating the zoo and xts objects; Merging time series objects; Rolling windows; Creating lags; Aggregating the zoo and xts objects; Plotting zoo and xts objects The plot.zoo functionThe plot.xts function; xts, zoo, or ts -- which one to use?; Summary; Chapter 5: Decomposition of Time Series Data; Technical requirement; The moving average function; The rolling window structure; The average method; The MA attributes; The simple moving average; Two-sided MA; A simple MA versus a two-sided MA; The time series components; The cycle component; The trend component; The seasonal component; The seasonal component versus the cycle component; White noise; The irregular component; The additive versus the multiplicative model; Handling multiplicative series},
author = {Krispin, Rami.},
isbn = {9781788624046},
pages = {438},
publisher = {Packt Publishing, Limited},
title = {{Hands-On Time Series Analysis with R : Perform Time Series Analysis and Forecasting Using R.}},
year = {2019}
}
@article{Mount2019,
abstract = {Description based upon print version of record. Part 2. Modeling methods. Intro -- Practical Data Science with R, Second Edition -- Nina Zumel and John Mount -- Copyright -- Dedication -- Brief Table of Contents -- Table of Contents -- Praise for the First Edition -- front matter -- Foreword -- Preface -- Acknowledgments -- About This Book -- What is data science? -- Roadmap -- Audience -- What is not in this book? -- Code conventions and downloads -- Working with this book -- Downloading the book's supporting materials/repository -- Book forum -- About the Authors -- About the Foreword Authors -- About the Cover Illustration -- Part 1. Introduction to data science Chapter 1. The data science process -- 1.1. The roles in a data science project -- 1.1.1. Project roles -- 1.2. Stages of a data science project -- 1.2.1. Defining the goal -- 1.2.2. Data collection and management -- 1.2.3. Modeling -- 1.2.4. Model evaluation and critique -- 1.2.5. Presentation and documentation -- 1.2.6. Model deployment and maintenance -- 1.3. Setting expectations -- 1.3.1. Determining lower bounds on model performance -- Summary -- Chapter 2. Starting with R and data -- 2.1. Starting with R -- 2.1.1. Installing R, tools, and examples -- 2.1.2. R programming 2.2. Working with data from files -- 2.2.1. Working with well-structured data from files or URLs -- 2.2.2. Using R with less-structured data -- 2.3. Working with relational databases -- 2.3.1. A production-size example -- Summary -- Chapter 3. Exploring data -- 3.1. Using summary statistics to spot problems -- 3.1.1. Typical problems revealed by data summaries -- 3.2. Spotting problems using graphics and visualization -- 3.2.1. Visually checking distributions for a single variable -- 3.2.2. Visually checking relationships between two variables -- Summary -- Chapter 4. Managing data 4.1. Cleaning data -- 4.1.1. Domain-specific data cleaning -- 4.1.2. Treating missing values -- 4.1.3. The vtreat package for automatically treating missing variables -- 4.2. Data transformations -- 4.2.1. Normalization -- 4.2.2. Centering and scaling -- 4.2.3. Log transformations for skewed and wide distributions -- 4.3. Sampling for modeling and validation -- 4.3.1. Test and training splits -- 4.3.2. Creating a sample group column -- 4.3.3. Record grouping -- 4.3.4. Data provenance -- Summary -- Chapter 5. Data engineering and data shaping -- 5.1. Data selection 5.1.1. Subsetting rows and columns -- 5.1.2. Removing records with incomplete data -- 5.1.3. Ordering rows -- 5.2. Basic data transforms -- 5.2.1. Adding new columns -- 5.2.2. Other simple operations -- 5.3. Aggregating transforms -- 5.3.1. Combining many rows into summary rows -- 5.4. Multitable data transforms -- 5.4.1. Combining two or more ordered data frames quickly -- 5.4.2. Principal methods to combine data from multiple tables -- 5.5. Reshaping transforms -- 5.5.1. Moving data from wide to tall form -- 5.5.2. Moving data from tall to wide form -- 5.5.3. Data coordinates -- Summary},
author = {Mount, John. and Zumel, Nina.},
isbn = {9781638352747},
publisher = {Manning Publications Co. LLC},
title = {{Practical Data Science with R}},
year = {2019}
}
@article{Oyana,
abstract = {Second edition. "First edition published 2015." In the five years since the publication of the first edition of Spatial Analysis: Statistics, Visualization, and Computational Methods, many new developments have taken shape regarding the implementation of new tools and methods for spatial analysis with R. The use and growth of artificial intelligence, machine learning and deep learning algorithms with a spatial perspective, and the interdisciplinary use of spatial analysis are all covered in this second edition along with traditional statistical methods and algorithms to provide a concept-based problem-solving learning approach to mastering practical spatial analysis. Spatial Analysis with R: Statistics, Visualization, and Computational Methods, Second Edition provides a balance between concepts and practicums of spatial statistics with a comprehensive coverage of the most important approaches to understand spatial data, analyze spatial relationships and patterns, and predict spatial processes. New in the Second Edition: Includes new practical exercises and worked-out examples using R Presents a wide range of hands-on spatial analysis worktables and lab exercises All chapters are revised and include new illustrations of different concepts using data from environmental and social sciences Expanded material on spatiotemporal methods, visual analytics methods, data science, and computational methods Explains big data, data management, and data mining This second edition of an established textbook, with new datasets, insights, excellent illustrations, and numerous examples with R, is perfect for senior undergraduate and first-year graduate students in geography and the geosciences.},
author = {Oyana, Tonny J.},
isbn = {9781000173451},
title = {{Spatial analysis with R : statistics, visualization, and computational methods}}
}
@article{Sarvotham2001,
abstract = {Most network traffic analysis and modeling studies lump all connections together into a single flow. Such aggregate traffic typically exhibits long-range-dependent (LRD) correlations and non-Gaussian marginal distributions. Importantly, in a typical aggregate traffic model, traffic bursts arise from many connections being active simultaneously. In this report, we develop a new framework for analyzing and modeling network traffic that moves beyond aggregation by incorporating connection-level information. A careful study of many traffic traces acquired in different networking situations reveals (in opposition to the aggregate modeling ideal) that traffic bursts typically arise from a single high-volume connection that dominates all others. We term such dominating connections alpha traffic. Alpha traffic is caused by large files transmissions over high bandwidth links and is extremely bursty (non-Gaussian). Stripping the alpha traffic from an aggregate trace leaves a beta traffic residual that is Gaussian, LRD, and shares the same fractal scaling exponent as the aggregate traffic. Beta traffic is caused by both small file transmissions and large files transmissions over low bandwidth links. In our alpha/beta traffic model, the heterogeneity of the network resources give rise to burstiness and heavy-tailed connection durations give rise to LRD.},
author = {Sarvotham, Shriram and Riedi, Rudolf and Baraniuk, Richard},
file = {:home/wcravens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sarvotham, Riedi, Baraniuk - 2001 - Connection-level Analysis and Modeling of Network Traffic.pdf:pdf},
title = {{Connection-level Analysis and Modeling of Network Traffic}},
year = {2001}
}
@article{Valenti2013,
abstract = {Traffic classification has received increasing attention in the last years. It aims at offering the ability to automatically recognize the application that has generated a given stream of packets from the direct and passive observation of the individual packets, or stream of packets, flowing in the network. This ability is instrumental to a number of activities that are of extreme interest to carriers, Internet service providers and network administrators in general. Indeed, traffic classification is the basic block that is required to enable any traffic management operations, from differentiating traffic pricing and treatment (e.g., policing, shaping, etc.), to security operations (e.g., firewalling, filtering, anomaly detection, etc.). Up to few years ago, almost any Internet application was using well-known transport layer protocol ports that easily allowed its identification. More recently, the number of applications using random or non-standard ports has dramatically increased (e.g. Skype, BitTorrent, VPNs, etc.). Moreover, often network applications are configured to use well-known protocol ports assigned to other applications (e.g. TCP port 80 originally reserved for Web traffic) attempting to disguise their presence. For these reasons, and for the importance of correctly classifying traffic flows, novel approaches based respectively on packet inspection, statistical and machine learning techniques, and behavioral methods have been investigated and are becoming standard practice. In this chapter, we discuss the main trend in the field of traffic classification and we describe some of the main proposals of the research community. We complete this chapter by developing two examples of behavioral classifiers: both use supervised machine learning algorithms for classifications, but each is based on different features to describe the traffic. After presenting them, we compare their performance using a large dataset, showing the benefits and drawback of each approach. {\textcopyright} 2013 Springer-Verlag Berlin Heidelberg.},
author = {Valenti, Silvio and Rossi, Dario and Dainotti, Alberto and Pescap{\`{e}}, Antonio and Finamore, Alessandro and Mellia, Marco},
doi = {10.1007/978-3-642-36784-7_6},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {123--147},
publisher = {Springer Verlag},
title = {{Reviewing traffic classification}},
volume = {7754},
year = {2013}
}
@article{Oudah2019,
abstract = {Network traffic classification is a vital task for service operators, network engineers, and security specialists to manage network traffic, design networks, and detect threats. Identifying the type/name of applications that generate traffic is a challenging task as encrypting traffic becomes the norm for Internet communication. Therefore, relying on conventional techniques such as deep packet inspection (DPI) or port numbers is not efficient anymore. This paper proposes a novel flow statistical-based set of features that may be used for classifying applications by leveraging machine learning algorithms to yield high accuracy in identifying the type of applications that generate the traffic. The proposed features compute different timings between packets and flows. This work utilises tcptrace to extract features based on traffic burstiness and periods of inactivity (idle time) for the analysed traffic, followed by the C5.0 algorithm for determining the applications that generated it. The evaluation tests performed on a set of real, uncontrolled traffic, indicated that the method has an accuracy of 79% in identifying the correct network application.},
author = {Oudah, Hussein and Ghita, Bogdan and Bakhshi, Taimur and Alruban, Abdulrahman and Walker, David J.},
doi = {10.1155/2019/5758437},
file = {:home/wcravens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oudah et al. - 2019 - Using Burstiness for Network Applications Classification.pdf:pdf},
journal = {Journal of Computer Networks and Communications},
publisher = {Hindawi Limited},
title = {{Using Burstiness for Network Applications Classification}},
volume = {2019},
year = {2019}
}
@misc{,
title = {{Bursty Traffic - an overview | ScienceDirect Topics}},
url = {https://www.sciencedirect.com/topics/engineering/bursty-traffic},
urldate = {2021-07-28}
}
@misc{,
title = {{Survival analysis - Wikipedia}},
url = {https://en.wikipedia.org/wiki/Survival_analysis},
urldate = {2021-07-28}
}
@misc{,
title = {{The Event Event: IEEE VIS 2016 Workshop on Temporal & Sequential Event Analysis}},
url = {https://eventevent.github.io/},
urldate = {2021-07-28}
}
@article{Gatalsky2004,
abstract = {In exploratory data analysis, the choice of tools depends on the data to be analyzed and the analysis tasks, i.e. the questions to be answered. The same applies to design of new analysis tools. In this paper, we consider a particular type of data: data that describe transient events having spatial and temporal references, such as earthquakes, traffic incidents, or observations of rare plants or animals. We focus on the task of detecting spatio-temporal patterns in event occurrences. We demonstrate the insufficiency of the existing techniques and approaches to event exploration and substantiate the need in a new exploratory tool. The technique of space-time cube, which has been earlier proposed for the visualization of movement in geographical space, possesses the required properties. However, it must be implemented so as to allow particular interactive manipulations: changing the viewing perspective, temporal focusing, and dynamic linking with a map display through simultaneous highlighting of corresponding symbols. We describe our implementation of the space-time cube technique and demonstrate by an example how it can be used for detecting spatio-temporal clusters of events.},
author = {Gatalsky, Peter and Andrienko, Natalia and Andrienko, Gennady},
doi = {10.1109/IV.2004.1320137},
journal = {Proceedings of the International Conference on Information Visualization},
keywords = {Data visualization,Exploratory data analysis,Space-time-cube,Spatio-temporal data},
pages = {145--152},
title = {{Interactive analysis of event data using space-time cube}},
volume = {8},
year = {2004}
}
@misc{,
title = {{(PDF) Interactive analysis of event data using space-time cube}},
url = {https://www.researchgate.net/publication/4085412_Interactive_analysis_of_event_data_using_space-time_cube},
urldate = {2021-07-28}
}
@misc{,
title = {{A Model for Predicting Frequencies of Random Events on JSTOR}},
url = {https://www.jstor.org/stable/2632170},
urldate = {2021-07-28}
}
@misc{,
title = {{Cumulative frequency analysis - Wikipedia}},
url = {https://en.wikipedia.org/wiki/Cumulative_frequency_analysis},
urldate = {2021-07-28}
}
@misc{,
title = {{Time series projection of events occurring randomly in time | Vose Software}},
url = {https://www.vosesoftware.com/riskwiki/Timeseriesprojectionofeventsoccurringrandomlyintime.php},
urldate = {2021-07-28}
}
