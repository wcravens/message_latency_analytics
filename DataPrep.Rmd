---
title: "Data Prep"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
---

```{r include=FALSE} 
# Other Modules we may want later ggplot2, randtests, eventInterval
library( tidyverse )
library( tibble )
library( dplyr )
# library( rio )
library( bit64 )
library( psych )
```

## Import message data from csv source.

```{r msgw_in_import}
.msgw_in_import <- rio::import( "./Data/eqfa-msgw-in-0709.txt", format="csv" )
```

```{r import_data_is_monotonic}
is_monotonic <- all(.msgw_in_import$ts_ns == cummax(.msgw_in_import$ts_ns) )
if( !is_monotonic ) stop("Input data is not monotonic on timestamp, ts_ns." )
print( "The MSGW In data is monotonic with regard to event timestamp.")
```

```{r quick_view_of_raw_import_data, echo=FALSE, eval=FALSE }
.msgw_in_import
```

# Prepare input data for down stream analysis

- Remove "PartyDetailsDefinitionRequest" Messages (they all have duplicate arrival times _and_ `null` processing time)
- Limit Observation time by `input_limit` in ns; Currently 120 Seconds.
- Normalize event `arrival_T` at $T_0 = 0$ Method: $T_i = T_i - T_0 \mbox{ for } i=0,...,n$.
- Convert latency/processing time `PNQM Latency (ms)` to `duration` in nanoseconds
- Coerce `Msg Type` into new [`factor`](https://r4ds.had.co.nz/factors.html) `type`
- Number events in `N`
- Spread out messages with duplicate arrival times; Method: $T_i = T_i + k \mbox{ for } i = 0,...,n \mbox{ for } k=0..d$ where $d = $ number of duplicates at $T_i$ 
- Calculate inter-message `delta_t` in nanoseconds
- Calculate event stop time, `departure_T`, in nanoseconds

```{r prepare_event_data}
input_time_limit <- 120e9 # Two minutes (120 Seconds) in ns

event_data <- .msgw_in_import %>%
  filter( !`Msg Type` %in% c( "PartyDetailsDefinitionRequest" ) ) %>%
  { if( input_time_limit ) filter(  ., ts_ns < first(ts_ns) + input_time_limit ) } %>%
  mutate(
    t = ts_ns - first(ts_ns),
    duration = as.numeric( na_if( `PNQM Latency (ms)`, "null" ) ) * 1e6,
    type = as.factor( `Msg Type` )
  ) %>%
  group_by( t ) %>%
  mutate(
    dup_count = n() - 1,
    dup_number = row_number() - 1
  ) %>%
  select( t, duration, type, dup_count, dup_number ) %>%
  ungroup() %>%
  arrange( t ) %>%
  mutate(
    N = row_number(),
    arrival_T = t + dup_number,
    delta_t = arrival_T - lag(arrival_T),
    departure_T = arrival_T + duration
  ) %>%
  select( N, arrival_T, delta_t, type, duration, departure_T )

event_data
```
Successfully loaded `r nrow( event_data )` observations from the first $input_limit$ nanoseconds of our event data.


# Calculate Number of Concurrent Events

- Create temporary lists of arrival and departure times for events; Add a step
size column of 1 and -1 respectively.
- Merge the arrival and departure tables together, order by time and then count
the cumulative sum of the assigned step size.
- Merge the concurrent event size data with the working event data on arrival
time so that we know the number of events in process when new events arrive
```{r concurrent_events_queue}
.arrivals <- event_data %>%
  filter( !is.na( departure_T ), departure_T != 0 ) %>%
  mutate( t = arrival_T, step = 1 ) %>%
  select( t, step )

.departures <- event_data %>%
  filter( !is.na( departure_T ), departure_T != 0 ) %>%
  mutate( t = departure_T, step = -1 ) %>%
  select( t, step )

.concurrent_event_count <- bind_rows( .arrivals, .departures ) %>%
  arrange( t ) %>%
  mutate( count = cumsum( step ))

event_data <- event_data %>%
  left_join( .concurrent_event_count, by=c('arrival_T' = 't' ) ) %>%
  rename( 'concurrent_event_count' = 'count' ) %>% 
  select( -'step' ) 
```

## Vizualizations concerning Event Arrival Time 
```{r viz-arrival_T}
hist( as.numeric( event_data$arrival_T ), breaks=120, col="blue", xlab = "Event Time in ns over the first two minutes of data.", main="Histogram of Event Freq per Sec" )

par(mfrow=c( 4, 1 ) )#, mai=c(0.1, 0.1, 0.1, 0.1) )
stripchart( as.numeric( head( event_data$arrival_T, 10000 ) ), pch=19, cex=0.5, col="blue", xlab="Event Time in ns", main="1-D Stripchart of Event Time; first 10000 observations." )
stripchart( as.numeric( head( event_data$arrival_T, 1000 ) ), pch=19, cex=0.5, col="blue", xlab="Event Time in ns", main="1-D Stripchart of Event Time; first 1000 observations." )
stripchart( as.numeric( head( event_data$arrival_T, 100 ) ), pch=19, cex=0.5, col="blue", xlab="Event Time in ns", main="1-D Stripchart of Event Time; first 100 observations." )
stripchart( as.numeric( head( event_data$arrival_T, 10 ) ), pch=19, cex=0.5, col="blue", xlab="Event Time in ns", main="1-D Stripchart of Event Time; first 10 observations." )
par( mfrow=c(1, 1) )

plot( head( event_data$arrival_T, 10000 ), head( event_data$delta_t, 10000 ), col="blue", pch=19, xlab="Event Time in ns", ylab="Inter-Event Delta_t in ns", main="Inter-Event Delta_t against Event Time" )
plot( head( event_data$arrival_T, 1000 ), head( event_data$delta_t, 1000 ), col="blue", pch=19, xlab="Event Time in ns", ylab="Inter-Event Delta_t in ns", main="Inter-Event Delta_t against Event Time" )
plot( head( event_data$arrival_T, 100 ), head( event_data$delta_t, 100 ), col="blue", pch=19, xlab="Event Time in ns", ylab="Inter-Event Delta_t in ns", main="Inter-Event Delta_t against Event Time" )
plot( head( event_data$arrival_T, 10 ), head( event_data$delta_t, 10 ), col="blue", pch=19, xlab="Event Time in ns", ylab="Inter-Event Delta_t in ns", main="Inter-Event Delta_t against Event Time" )
```

## Visualizations concering inter-event delta_t
```{r viz-delta_t}
. <- event_data %>%
  #slice( -1 ) %>%
  mutate( delta_t = replace_na( as.numeric( delta_t ), 0 ) ) %>%
  select( delta_t )
delta_t = .$delta_t

str(delta_t)
summary(delta_t)
describe(delta_t) 
acf(delta_t)
pacf(delta_t)

plot( event_data$arrival_T, delta_t, col="blue", pch=19, xlab="Event Time in ns", ylab="Inter-Event Delta_t in ns", main="Inter-Event Delta_t against Event Time" )

plot( head( delta_t, 1000 ), head( event_data$duration, 1000 ), pch=19, col="blue", xlab="Inter-Event Delta_t", ylab="Duration of Event in ns", main="Event Duration against Inter-Event Delta_t" )

hist( as.numeric( delta_t), col="blue", main="Histogram of Inter-event Delta_t", xlab="Delta_t in Nanoseconds")
hist( log( as.numeric( delta_t)), col="blue", main="Histogram of log( Inter-event Delta_t )", xlab="log(Delta_t) in Nanoseconds")

{
  qqnorm( as.numeric( delta_t ) )
  qqline(as.numeric(delta_t), distribution=qnorm)
}
{
  qqplot(x=qexp(ppoints(1000)), y=as.numeric(delta_t), main="Exponential Q-Q Plot",
         xlab="Theoretical Quantiles", ylab= "Delta_t Quantiles")
  qqline(as.numeric(delta_t), distribution=qexp)
}
```

## Visualizations concering the Number of Concurrent Events over Time (Queueing Process)
```{r explore_concurent_events}

  
#plot( event_data$t, event_data$size, type="l", col="blue", pch=19, cex=0.5, main="Concurrent Event Count at Time t.", xlab='Time t in Nanoseconds', ylab="Concurrent event count" )
#hist( log( event_data$size ), col="blue", main="Histogram of log( Concurrent Event Count )", xlab="log( Concurrent Event Count )")
```
```{r viz_concurrent_vs_duration}

plot( lag( event_data$concurrent_event_count), event_data$duration, col="blue", pch=19, cex=0.5, main="Impact of current queue size on new message's eventual latency.",
      xlab="Message Queue Size when New Message Arrived", ylab="Latency Experienced by the New Message")
```


```{r echo=FALSE}
print( "Finished Successfully!" )
print( "======================" )
```
