---
title: "Data Prep"
output:
  html_notebook: default
  html_document:
    df_print: paged
  pdf_document: default
---

```{r include=FALSE} 
# Other Modules we may want later ggplot2, randtests, eventInterval
library( tidyverse )
library( tibble )
library( dplyr )
# library( rio )
library( bit64 )
library( psych )
```

## Import message data from csv source.

```{r msgw_in_import}
.msgw_in_import <- rio::import( "./Data/eqfa-msgw-in-0709.txt", format="csv" )
```

```{r import_data_is_monotonic}
is_monotonic <- all(.msgw_in_import$ts_ns == cummax(.msgw_in_import$ts_ns) )
if( !is_monotonic ) stop("Input data is not monotonic on timestamp, ts_ns." )
print( "The MSGW In data is monotonic with regard to event timestamp.")
```

```{r quick_view_of_raw_import_data, echo=FALSE, eval=FALSE }
.msgw_in_import
```

# Prepare input data for down stream analysis

1. Limit data set to a couple of minutes to speed up initial analytics.

2. Remove "PartyDetailsDefinitionRequest" Messages (they all have duplicate arrival times _and_ `null` processing time)

3. Normalize event `arrival_T` at $T_0 = 0$ Method: $T_i = T_i - T_0 \mbox{ for } i=0,...,n$.

4. Convert latency/processing time `PNQM Latency (ms)` to `duration` in nanoseconds

5. Use `Msg Type` as new factor `type`

6. Identify and label events with duplicate time-stamps.  Add a group total count and each individual event's number in the duplicated group to the data.

7. Number all events sequentially starting at 1 and incrementing by 1 for each new event arrival.  Store the individual event number in `N`

8. Spread out messages with duplicate arrival times by altering the arrival timestamp; Method: $T_i = T_i + k \mbox{ for } i = 0,...,n \mbox{ for } k=0..d$ where $d = $ number of duplicates at $T_i$ 

We can find the specifics later.  But I did look at the impact of this and
noticed that the amount of 'adjustment' necessary was considerably smaller
than the next 'smallest' gap between events.  An other method would have 
been to increase the precision of our number and using the least significant 
part to spread the message out in fraction of time about the duplicated 
arrival time.  The first option was considered much more reasonable and
easier to ensure we get correct.
    
9. Calculate inter-message `delta_t` in nanoseconds

10. Calculate event stop time, `departure_T`, in nanoseconds

11. Build the new data table out of the `N`, `arrival_t`, `delta_t`, `type`, `duration`, and `departure_T` fields.


```{r prepare_event_data}
time_limit <- 2 * 60 * 1e9 # Two minutes in ns

event_data <- .msgw_in_import %>%
 
  { if( time_limit ) filter(  ., ts_ns < first(ts_ns) + time_limit ) } %>% #  1.
  
  filter( !`Msg Type` %in% c( "PartyDetailsDefinitionRequest" ) ) %>% #       2.
  
  mutate(
    t = ts_ns - first(ts_ns),  #                                              3.
    duration = as.numeric( na_if( `PNQM Latency (ms)`, "null" ) ) * 1e6, #    4.
    type = as.factor( `Msg Type` ) #                                          5.
  ) %>%
  
  group_by( t ) %>%
  mutate(
    duplicate_count = n() - 1, #                                              6.
    duplicate_number = row_number() - 1
  ) %>%
  select( t, duration, type, duplicate_count, duplicate_number ) %>%
  ungroup() %>%
  arrange( t ) %>%
  
  mutate(
    N = row_number(), #                                                       7.
    arrival_T = t + duplicate_number, #                                       8.
    delta_t = arrival_T - lag(arrival_T), #                                   9.
    departure_T = arrival_T + duration #                                     10.
  ) %>%
  select( N, arrival_T, delta_t, type, duration, departure_T ) # 11.
```

Successfully loaded `r nrow( event_data )` observations from the first `r time_limit` nanoseconds of our event data.


## Vizualizations concerning Event Arrival Time 
```{r viz-arrival_T}
hist( as.numeric( event_data$arrival_T ), breaks=120, col="blue", xlab = "Event Time in ns over the first two minutes of data.", main="Histogram of Event Freq per Sec" )

par(mfrow=c( 4, 1 ) )#, mai=c(0.1, 0.1, 0.1, 0.1) )
stripchart( as.numeric( head( event_data$arrival_T, 10000 ) ), pch=19, cex=0.5, col="blue", xlab="Event Time in ns", main="1-D Stripchart of Event Time; first 10000 observations." )
stripchart( as.numeric( head( event_data$arrival_T, 1000 ) ), pch=19, cex=0.5, col="blue", xlab="Event Time in ns", main="1-D Stripchart of Event Time; first 1000 observations." )
stripchart( as.numeric( head( event_data$arrival_T, 100 ) ), pch=19, cex=0.5, col="blue", xlab="Event Time in ns", main="1-D Stripchart of Event Time; first 100 observations." )
stripchart( as.numeric( head( event_data$arrival_T, 10 ) ), pch=19, cex=0.5, col="blue", xlab="Event Time in ns", main="1-D Stripchart of Event Time; first 10 observations." )
par( mfrow=c(1, 1) )

plot( head( event_data$arrival_T, 10000 ), head( event_data$delta_t, 10000 ), col="blue", pch=19, xlab="Event Time in ns", ylab="Inter-Event Delta_t in ns", main="Inter-Event Delta_t against Event Time" )
plot( head( event_data$arrival_T, 1000 ), head( event_data$delta_t, 1000 ), col="blue", pch=19, xlab="Event Time in ns", ylab="Inter-Event Delta_t in ns", main="Inter-Event Delta_t against Event Time" )
plot( head( event_data$arrival_T, 100 ), head( event_data$delta_t, 100 ), col="blue", pch=19, xlab="Event Time in ns", ylab="Inter-Event Delta_t in ns", main="Inter-Event Delta_t against Event Time" )
plot( head( event_data$arrival_T, 10 ), head( event_data$delta_t, 10 ), col="blue", pch=19, xlab="Event Time in ns", ylab="Inter-Event Delta_t in ns", main="Inter-Event Delta_t against Event Time" )
```

## Visualizations concering inter-event delta_t
```{r viz-delta_t}
. <- event_data %>%
  #slice( -1 ) %>%
  mutate( delta_t = replace_na( as.numeric( delta_t ), 0 ) ) %>%
  select( delta_t )
delta_t = .$delta_t

str(delta_t)
summary(delta_t)
describe(delta_t) 
acf(delta_t)
pacf(delta_t)

plot( event_data$arrival_T, delta_t, col="blue", pch=19, xlab="Event Time in ns", ylab="Inter-Event Delta_t in ns", main="Inter-Event Delta_t against Event Time" )

plot( head( delta_t, 1000 ), head( event_data$duration, 1000 ), pch=19, col="blue", xlab="Inter-Event Delta_t", ylab="Duration of Event in ns", main="Event Duration against Inter-Event Delta_t" )

hist( as.numeric( delta_t), col="blue", main="Histogram of Inter-event Delta_t", xlab="Delta_t in Nanoseconds")
hist( log( as.numeric( delta_t)), col="blue", main="Histogram of log( Inter-event Delta_t )", xlab="log(Delta_t) in Nanoseconds")

{
  qqnorm( as.numeric( delta_t ) )
  qqline(as.numeric(delta_t), distribution=qnorm)
}
{
  qqplot(x=qexp(ppoints(1000)), y=as.numeric(delta_t), main="Exponential Q-Q Plot",
         xlab="Theoretical Quantiles", ylab= "Delta_t Quantiles")
  qqline(as.numeric(delta_t), distribution=qexp)
}
```

## Visualizations concering the Number of Concurrent Events over Time (Queueing Process)
```{r explore_concurent_events}

  
#plot( event_data$t, event_data$size, type="l", col="blue", pch=19, cex=0.5, main="Concurrent Event Count at Time t.", xlab='Time t in Nanoseconds', ylab="Concurrent event count" )
#hist( log( event_data$size ), col="blue", main="Histogram of log( Concurrent Event Count )", xlab="log( Concurrent Event Count )")
```
```{r viz_concurrent_vs_duration}

plot( lag( event_data$concurrent_event_count), event_data$duration, col="blue", pch=19, cex=0.5, main="Impact of current queue size on new message's eventual latency.",
      xlab="Message Queue Size when New Message Arrived", ylab="Latency Experienced by the New Message")
```


```{r echo=FALSE}
print( "Finished Successfully!" )
print( "======================" )
```
